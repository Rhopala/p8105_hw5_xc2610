---
title: "P8105_HW5_xc2610"
author: "Xuanhe Chen"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(ggridges)
library(p8105.datasets)
library(viridis)
library(dplyr)

knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  fig.width = 8,
  fig.height = 6,
  out.width = "90%"
)

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

The raw data contains more than 52,000 criminal homicides Washington Post collected over the past decade in 50 of the largest American cities. The data contains 12 columns, includes: UID, report data, vitim's first, last name, race, age, sex, city and state and exact location (latitude and longidute) being found, and disposition.

```{r}
# load and edit data, create the city_state variable required. 
homicide_df = 
  read_csv("./data/homicide-data.csv", na = c("", "Unknown")) %>%
  mutate(
    city_state = str_c(city, state),
    resolution = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest" ~ "unsolved",
      disposition == "Closed by arrest" ~ "solved",
    )) %>%
  relocate(city_state) %>%
  filter(city_state != "TulsaAL")
```
```{r}
# pull the reqired data
baltimore_df =
  homicide_df %>%
  filter(city_state == "BaltimoreMD")

# make a test on the data
baltimore_summary =
  baltimore_df %>%
  summarize(
    unsolved = sum(resolution == "unsolved"),
    n = n()
  )

baltimore_test =
  prop.test(
    x = baltimore_summary %>% pull(unsolved), 
    n = baltimore_summary %>% pull(n))

baltimore_test %>%
  broom::tidy()
```

```{r}
# create a function to run test on each city
prop_test_function = function(city_df) {
  
  city_summary =
  city_df %>%
  summarize(
    unsolved = sum(resolution == "unsolved"),
    n = n()
  )

  city_test =
    prop.test(
      x = city_summary %>% pull(unsolved), 
      n = city_summary %>% pull(n))
  
  return(city_test)
}
```

```{r}
# test the test
prop_test_function(baltimore_df)

homicide_df %>%
  filter(city_state == "AlbuquerqueNM") %>%
  prop_test_function()
```

```{r}
# map the test to all cities and edit data format
results_df =
  homicide_df %>%
  nest(data = uid:resolution) %>%
  mutate(
    test_results = map(data, prop_test_function),
    tidy_results = map(test_results, broom::tidy)
  ) %>%
  
  select(city_state, tidy_results) %>%
  unnest(tidy_results) %>%
  select(city_state, estimate, starts_with("conf"))
```

```{r}
# plot the result with error bars
results_df %>%
  mutate(city_state = fct_reorder(city_state, estimate)) %>%
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
  ggtitle("Proportion of Unsolved Homicides in last decade in 50 largest US Cities")
```

## Problem 2



```{r, message=FALSE}
# read each files address
file_names <- list.files("./data/P2_data/", full.names = TRUE)

# map a function binding address and each file together
file_combined <- purrr::map_df(file_names, function(x) {
  data <- read_csv(x)
	cbind(arm_id = x, data)
	})

# drop unnecessary parts in file names
file_combined <- 
  file_combined %>% 
  mutate(arm_id = str_remove(arm_id, "./data/P2_data/")) %>%
  mutate(arm_id = str_remove(arm_id, ".csv"))

# turn the data frame from wide to long for plotting
file_combined_long <- gather(file_combined, week, observations, week_1:week_8, factor_key=TRUE)
```

```{r}
#plot the data
  ggplot(file_combined_long, aes(x = week, y = observations, group = arm_id, color = arm_id)) +  geom_line() + geom_point() + theme_bw() + ggtitle("Observations Over Time for Control and Experimental Subjects")
```

From the plot, we can see that subjects in the control arm have significantly lower average observation measures than experimental arm. The experimental subjects also have a trend of rising over time, which wasn't obvious in the subjects of control arm. 

## Problem 3


```{r}
#  loads the iris dataset from the tidyverse package and introduces some missing values in each column
set.seed(10)

iris_with_missing = iris %>% 
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species))

# visualize the data as table
knitr::kable(iris_with_missing)
```

```{r}
# create a function to replace the NA's with proper values

fill_in_missing = function(vector) { # function take vector as parameter
  
  # if the parameter is numeric, replace NAs with the mean of exist values
  if(is.numeric(vector)) {
    vector[is.na(vector)] <- mean(vector, na.rm=TRUE)
  }
  
  # if the parameter is character, replace NAs with "virginica"
  if(is.character(vector)){
    vector[is.na(vector)] <- "virginica"
  }
  
  return(vector) # return updated vector
}
```

```{r}
# map the function to the whole data frame
iris_filled <- map_df(iris_with_missing, fill_in_missing)

# visualize the data as table
knitr::kable(iris_filled)
```
